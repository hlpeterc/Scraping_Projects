# -*- coding: utf-8 -*-
"""Scraping Project 2: Kith.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fLlJOB80crAMxadoSZMNk2OVXVU_Fv5L

## Scrape multiple pages from Kith
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

"""**1. Store the pages that we want to scrape in a list.**"""

url_list = []
kith_list = ['outerwear', 'footwear']
for i in kith_list:
  url = 'https://kith.com/collections/kith-' + i
  url_list.append(url)

url_list

"""**2. Prepare the column names and the empty dataframe.**"""

column_list = ['Product Name', 'Color', 'Price (USD)', 'Type']

df = pd.DataFrame([], columns = column_list)
df

"""**3. Write a `for` loop to scrape the `name`, `color`, and `price` of each product. Assign them with different types.**"""

w = 0
while w < len(url_list):

  # Prepare thr soup #
  page = requests.get(url_list[w])
  soup = BeautifulSoup(page.text, 'lxml')

  # Find all the name, color, and price sets #
  nested = soup.find('div', class_ = 'collection-layout')

  name = nested.find_all('h1', class_ = 'product-card__title')
  color = nested.find_all('h2', class_ = 'product-card__color')
  price = nested.find_all('span', class_ = "product-card__price")

  # Get all the text in the sets, append them into different empty lists #
  name_list = []
  color_list = []
  price_list = []
  type_list = []

  for i in range(len(name)):
    single_name = name[i].text
    name_list.append(single_name)

  for j in range(len(color)):
    single_color = color[j].text
    color_list.append(single_color)

  for k in range(len(price)):
    single_price = price[k].text.replace('\n', '')
    single_price = single_price.replace('$', '')
    single_price = single_price.replace(',', '')
    price_list.append(single_price)

  for p in range(len(name)):
    if w == 0:
      type_list.append('Outerwear')
    if w == 1:
      type_list.append('Footwear')

  # Use lists to create a dataframe, loop again to the next page #
  dataframe = pd.DataFrame(list(zip(name_list, color_list, price_list, type_list)),
               columns = column_list)
  df = df.append(dataframe)
  w += 1

pd.set_option('display.max_rows', 100)

df["Price (USD)"] = df["Price (USD)"].astype(float)

df.info()

"""**4. Sort by the price.**"""

df.sort_values(by='Price (USD)', ascending=False)

import seaborn as sns
sns.set(rc={'figure.figsize':(11.7,8.27)})

df.groupby(["Color"]).size()

sns.countplot(x = 'Type', data = df).set(xlabel='Type', ylabel='Number')

df[df["Type"] == "Outerwear"].describe()

df[df["Type"] == "Footwear"].describe()

sns.violinplot(x = 'Type', y = 'Price (USD)', data = df)

sns.swarmplot(x = 'Type', y = 'Price (USD)', data = df)

sns.boxplot(x = 'Type', y = 'Price (USD)', data = df)

type_logit = []
for i in df["Type"]:
  if i == "Footwear":
    type_logit.append(0)
  else:
    type_logit.append(1)

df["Type_logit"] = type_logit
df

vis = sns.regplot(x = 'Price (USD)', y = 'Type_logit', data = df, logistic = True)
vis

import statsmodels.api as sm

#sm.Logit(y,x)

log_reg = sm.Logit(df['Type_logit'], df['Price (USD)']).fit()
log_reg.summary()